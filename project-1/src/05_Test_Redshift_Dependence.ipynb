{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVFxKTbwVtX9"
   },
   "source": [
    "## Test redshift independce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "256hUnGu565i"
   },
   "outputs": [],
   "source": [
    "# get distance moduli for redshifts using reconstructed mu-z funciton\n",
    "GRB['dL'] = calculate_dL(GRB['mu'].to_numpy()) \n",
    "GRB['dL_err'] = calculate_dL_err(GRB['dL'].to_numpy(), GRB['mu_err'].to_numpy())\n",
    "GRB['L'] = calculate_L(GRB['dL'].to_numpy(), GRB['P_bolo'].to_numpy()) \n",
    "GRB['L_err'] = calculate_L_err(GRB['dL_err'].to_numpy(), GRB['dL'].to_numpy(), GRB['P_bolo_err'].to_numpy(), GRB['P_bolo'].to_numpy(), GRB['L'].to_numpy()) \n",
    "GRB['E_iso'] = calculate_E_iso(GRB['dL'].to_numpy(), GRB['S_bolo'].to_numpy(), GRB['z'].to_numpy())\n",
    "GRB['E_iso_err'] = calculate_E_iso_err(GRB['L'].to_numpy(), GRB['dL_err'].to_numpy(), GRB['dL'].to_numpy(), GRB['S_bolo_err'].to_numpy(), GRB['S_bolo'].to_numpy(), GRB['z'].to_numpy())\n",
    "GRB['E_gamma'] = calculate_E_gamma(GRB['E_iso'].to_numpy(), GRB['F_beam'].to_numpy())\n",
    "GRB['E_gamma_err'] = calculate_E_gamma_err(GRB['E_iso'].to_numpy(), GRB['F_beam'].to_numpy(), GRB['E_gamma'].to_numpy(), GRB['E_iso_err'].to_numpy(), GRB['F_beam_err'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzXnFX391x6N"
   },
   "outputs": [],
   "source": [
    "# Since E_peak, error bars are asymmetric, just take the average of the lower and upper errors and then do the fit.\n",
    "GRB['E_peak_err'] = GRB[['E_peak_err_min','E_peak_err_max']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCV9eJdK3oQI"
   },
   "source": [
    " quantities with a subscript ‘i’ indicate that they are measured in the comoving frame, which are related to the\n",
    "quantities in the observer frame by τlag,i = τlag(1 + z)\n",
    "−1\n",
    ", τRT,i = τRT(1 + z)\n",
    "−1\n",
    ", Vi = V (1 + z) and Ep,i = Ep(1 + z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRzQl8Bc3rUT"
   },
   "outputs": [],
   "source": [
    "GRB['T_lag_i'] = GRB['T_lag'] / (1. + GRB['z'])\n",
    "GRB['T_lag_i_err'] = GRB['T_lag_err'] / (1. + GRB['z'])\n",
    "GRB['T_RT_i'] = GRB['T_RT'] / (1. + GRB['z'])\n",
    "GRB['T_RT_i_err'] = GRB['T_RT_err'] / (1. + GRB['z'])\n",
    "GRB['V_i'] = GRB['V'] * (1. + GRB['z'])\n",
    "GRB['V_i_err'] = GRB['V_err'] * (1. + GRB['z'])\n",
    "GRB['E_peak_i'] = GRB['E_peak'] * (1. + GRB['z'])\n",
    "GRB['E_peak_i_err'] = GRB['E_peak_err'] * (1. + GRB['z'])\n",
    "GRB['E_peak_i_err_min'] = GRB['E_peak_err_min'] * (1. + GRB['z'])\n",
    "GRB['E_peak_i_err_max'] = GRB['E_peak_err_max'] * (1. + GRB['z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDERA7baoWH6"
   },
   "outputs": [],
   "source": [
    "# normalized\n",
    "GRB['_T_lag_i'] = GRB['T_lag_i'] / 0.1\n",
    "GRB['_T_lag_i_err'] = GRB['T_lag_i_err'] / 0.1\n",
    "GRB['_V_i'] = GRB['V_i'] / 0.02\n",
    "GRB['_V_i_err'] = GRB['V_i_err'] / 0.02\n",
    "GRB['_E_peak_i'] = GRB['E_peak_i'] / 300\n",
    "GRB['_E_peak_i_err'] = GRB['E_peak_i_err'] / 300\n",
    "GRB['_E_peak_i_err_min'] = GRB['E_peak_i_err_min'] / 300\n",
    "GRB['_E_peak_i_err_max'] = GRB['E_peak_i_err_max'] / 300\n",
    "GRB['_T_RT_i'] = GRB['T_RT_i'] / 0.1\n",
    "GRB['_T_RT_i_err'] = GRB['T_RT_i_err'] / 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3qCswSbz-Kb",
    "outputId": "04c00026-f4d7-455f-9ae4-76863dfe5a49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:726: RuntimeWarning: invalid value encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# log transformation\n",
    "GRB['log_T_lag_i'] = np.log10(GRB['_T_lag_i'])\n",
    "GRB['log_T_lag_i_err'] = abs(GRB['_T_lag_i_err'] / (GRB['_T_lag_i'] * np.log(10)))\n",
    "GRB['log_V_i'] = np.log10(GRB['_V_i'])\n",
    "GRB['log_V_i_err'] = abs(GRB['_V_i_err'] / (GRB['_V_i'] * np.log(10)))\n",
    "GRB['log_E_peak_i'] = np.log10(GRB['_E_peak_i'])\n",
    "GRB['log_E_peak_i_err'] = abs(GRB['_E_peak_i_err'] / (GRB['_E_peak_i'] * np.log(10)))\n",
    "GRB['log_E_peak_i_err_min'] = abs(GRB['_E_peak_i_err_min'] / (GRB['_E_peak_i'] * np.log(10)))\n",
    "GRB['log_E_peak_i_err_max'] = abs(GRB['_E_peak_i_err_max'] / (GRB['_E_peak_i'] * np.log(10)))\n",
    "GRB['log_T_RT_i'] = np.log10(GRB['_T_RT_i'])\n",
    "GRB['log_T_RT_i_err'] = abs(GRB['_T_RT_i_err'] / (GRB['_T_RT_i'] * np.log(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUSinXmz2CZM"
   },
   "outputs": [],
   "source": [
    "GRB['log_L'] = np.log10(GRB['L'])\n",
    "GRB['log_L_err'] = abs(GRB['L_err'] / (GRB['L'] * np.log(10)))\n",
    "GRB['log_E_iso'] = np.log10(GRB['E_iso'])\n",
    "GRB['log_E_iso_err'] = abs(GRB['E_iso_err'] / (GRB['E_iso'] * np.log(10)))\n",
    "GRB['log_E_gamma'] = np.log10(GRB['E_gamma'])\n",
    "GRB['log_E_gamma_err'] = abs(GRB['E_gamma_err'] / (GRB['E_gamma'] * np.log(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KffBF3g55R4"
   },
   "outputs": [],
   "source": [
    "# split the data in to low-z, high-z and All-z\n",
    "low_z_GRB = GRB[GRB['z']<=1.4]\n",
    "high_z_GRB = GRB[GRB['z']>1.4]\n",
    "All_z_GRB = GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpCO1hgtybNj"
   },
   "outputs": [],
   "source": [
    "# filter GRBs seperately for each correlation, such that required data are present for each GRB\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVONzeqtH5vK"
   },
   "outputs": [],
   "source": [
    "def log_likelihood(theta, x, y, xerr, yerr):\n",
    "    b, a, sigma_int = theta\n",
    "    model = b * x + a\n",
    "    sigma2 = sigma_int**2 + yerr**2 + b**2 * xerr**2\n",
    "    return -0.5 * np.sum((y - model) ** 2 / sigma2 + np.log(sigma2))\n",
    "\n",
    "def log_prior(theta):\n",
    "    b, a, sigma_int = theta\n",
    "    if sigma_int > 0:\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "def log_posterior(theta, x, y, xerr, yerr):\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta, x, y, xerr, yerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "id": "-yPAqW7e7pDi",
    "outputId": "7324f2d0-87c1-4528-e775-e50394fcf834",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlations = {\n",
    "    'T_lag-L' : ('log_T_lag_i', 'log_L', 'log_T_lag_i_err', 'log_L_err'),\n",
    "    'V-L' : ('log_V_i', 'log_E_iso', 'log_V_i_err', 'log_E_iso_err'),\n",
    "    'E_peak-L' : ('log_E_peak_i', 'log_L', 'log_E_peak_i_err', 'log_L_err'),\n",
    "    'E_peak-E_gamma' : ('log_E_peak_i', 'log_E_gamma', 'log_E_peak_i_err', 'log_E_gamma_err'),\n",
    "    'T_RT-L' : ('log_T_RT_i', 'log_L', 'log_T_RT_i_err', 'log_L_err'),\n",
    "    'E_peak-E_iso' : ('log_E_peak_i', 'log_E_iso', 'log_E_peak_i_err', 'log_E_iso_err')\n",
    "}\n",
    "\n",
    "# Calculate best fit line with uncertainities(Bayesian approach) using emcee\n",
    "GRB_samples = (low_z_GRB, high_z_GRB, All_z_GRB)\n",
    "sample_types =  ('low-z', 'high-z', 'All-z')\n",
    "colors = ('b','r','k')\n",
    "\n",
    "# MCMC parameters\n",
    "nwalkers, ndim = 64, 3\n",
    "nsteps, nburns = 10000, 5000\n",
    "\n",
    "# empty dictionary to save best fit parameters and uncertainities\n",
    "BestFitParameters = { \n",
    "    'T_lag-L':{'low-z':None, 'high-z':None, 'All-z':None},\n",
    "    'V-L':{'low-z':None, 'high-z':None, 'All-z':None},\n",
    "    'E_peak-L':{'low-z':None, 'high-z':None, 'All-z':None},\n",
    "    'E_peak-E_gamma':{'low-z':None, 'high-z':None, 'All-z':None},\n",
    "    'T_RT-L':{'low-z':None, 'high-z':None, 'All-z':None},\n",
    "    'E_peak-E_iso':{'low-z':None, 'high-z':None, 'All-z':None}\n",
    "}\n",
    "\n",
    "for i, correlation in enumerate(correlations):\n",
    "\n",
    "    luminosities = correlations[correlation]\n",
    "\n",
    "    '''\n",
    "    # create empty figure object for time series (steps) plot of parameters in chain\n",
    "    fig1 = plt.figure(constrained_layout=True, figsize=(15,5))\n",
    "    gs1 = gridspec.GridSpec(nrows=1, ncols=3, figure=fig1)\n",
    "    '''\n",
    "\n",
    "    # create empty figure object for corner plots (confidence contours and marginalized PDFs of parameters)\n",
    "    fig2 = plt.figure(figsize=(5, 5))\n",
    "    fig2.patch.set_facecolor('white')\n",
    "\n",
    "    for k, (GRB_sample, sample_type, color) in enumerate(zip(GRB_samples, sample_types, colors)):\n",
    "\n",
    "        df = GRB_sample.filter(luminosities).dropna()\n",
    "        \n",
    "        x = df[luminosities[0]].to_numpy()\n",
    "        y = df[luminosities[1]].to_numpy()\n",
    "        xerr = df[luminosities[2]].to_numpy()\n",
    "        yerr = df[luminosities[3]].to_numpy()\n",
    "\n",
    "        starting_guesses = np.random.rand(nwalkers, ndim)\n",
    "        \n",
    "        sampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior, args=(x, y, xerr, yerr))\n",
    "        sampler.run_mcmc(starting_guesses, nsteps)\n",
    "\n",
    "        labels = ['b', 'a', 'sigma_int']\n",
    "        '''\n",
    "        # time series plot of parameters\n",
    "        samples = sampler.get_chain()\n",
    "        gs11 = gridspec.GridSpecFromSubplotSpec(nrows=3, ncols=1, subplot_spec=gs1[k])\n",
    "\n",
    "        for j in range(ndim):\n",
    "            ax = fig1.add_subplot(gs11[j])\n",
    "            ax.plot(samples[..., j], 'k', alpha=0.3)\n",
    "            ax.set_xlim(0, len(samples))\n",
    "            ax.set_ylabel(labels[j])\n",
    "            ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "        #axes[-1].set_xlabel(\"step number\");\n",
    "        '''\n",
    "        # corner plots\n",
    "        flat_samples = sampler.get_chain(discard=nburns, flat=True)\n",
    "        corner.corner(flat_samples, labels=labels, color=color,fig=fig2)\n",
    "\n",
    "        # save best fit values(mean) and uncertainities(std) of parameters in a dictionary\n",
    "        BestFitParameters[correlation][sample_type] = {\n",
    "                'a' : np.mean(flat_samples[:, 1]), \n",
    "                'a_err' : np.std(flat_samples[:, 1]),\n",
    "                'b' : np.mean(flat_samples[:, 0]), \n",
    "                'b_err' : np.std(flat_samples[:, 0]),\n",
    "                'sigma_int' : np.mean(flat_samples[:, 2]),\n",
    "                'sigma_int_err' : np.std(flat_samples[:, 2])\n",
    "        }\n",
    "    \n",
    "        fig2.axes[0].annotate(sample_type, xy=(0.95*2.5, 0.95-k*0.2), xycoords='axes fraction',color=color)\n",
    "  \n",
    "    fig2.suptitle(correlation)\n",
    "\n",
    "    #fig1.savefig('time_series_of_params.png')\n",
    "    fig2.savefig(correlation+'_corner_plot.png')\n",
    "    #fig1.show()\n",
    "    fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwibAn2fm5bV"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(runDir, 'BestFitParameters.pickle'), 'wb') as handle:\n",
    "    pickle.dump(BestFitParameters, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-b8XSKRAoKPg"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(runDir, 'BestFitParameters.pickle'), 'rb') as handle:\n",
    "    BestFitParameters = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJyGb68Prm0s"
   },
   "outputs": [],
   "source": [
    "def flatten_dict(nested_dict):\n",
    "    res = {}\n",
    "    if isinstance(nested_dict, dict):\n",
    "        for k in nested_dict:\n",
    "            flattened_dict = flatten_dict(nested_dict[k])\n",
    "            for key, val in flattened_dict.items():\n",
    "                key = list(key)\n",
    "                key.insert(0, k)\n",
    "                res[tuple(key)] = val\n",
    "    else:\n",
    "        res[()] = nested_dict\n",
    "    return res\n",
    "\n",
    "\n",
    "def nested_dict_to_df(values_dict):\n",
    "    flat_dict = flatten_dict(values_dict)\n",
    "    df = pd.DataFrame.from_dict(flat_dict, orient=\"index\")\n",
    "    df.index = pd.MultiIndex.from_tuples(df.index)\n",
    "    df = df.unstack(level=-1)\n",
    "    df.columns = df.columns.map(\"{0[1]}\".format)\n",
    "    return df\n",
    "\n",
    "table = nested_dict_to_df(BestFitParameters)\n",
    "\n",
    "!pip install tabulate\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(tabulate(table, headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBg8IP8Ry9-k"
   },
   "outputs": [],
   "source": [
    "correlations = {\n",
    "    'T_lag-L' : {'features': ('log_T_lag_i', 'log_L', 'log_T_lag_i_err', 'log_L_err'), 'ylim':(50, 54), 'xlim':(-2.0,2.0)},\n",
    "    'V-L' : {'features': ('log_V_i', 'log_L', 'log_V_i_err', 'log_L_err'), 'ylim':(50, 54), 'xlim':(-1.0,2.0)},\n",
    "    'E_peak-L' : {'features': ('log_E_peak_i', 'log_L', 'log_E_peak_i_err', 'log_L_err'), 'ylim':(49, 54), 'xlim':(-1.5,1.5)},\n",
    "    'E_peak-E_gamma' : {'features': ('log_E_peak_i', 'log_E_gamma', 'log_E_peak_i_err', 'log_E_gamma_err'), 'ylim':(48, 52), 'xlim':(-1.5,1.5)},\n",
    "    'T_RT-L' : {'features': ('log_T_RT_i', 'log_L', 'log_T_RT_i_err', 'log_L_err'), 'ylim':(50, 54), 'xlim':(-1.0,2.0)},\n",
    "    'E_peak-E_iso' : {'features': ('log_E_peak_i', 'log_E_iso', 'log_E_peak_i_err', 'log_E_iso_err'), 'ylim':(50, 55), 'xlim':(-1.5,1.5)}\n",
    "}\n",
    "\n",
    "GRB_samples = (low_z_GRB, high_z_GRB, All_z_GRB)\n",
    "sample_types =  ('low-z', 'high-z', 'All-z')\n",
    "colors = ('b','r','k')\n",
    "\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(15,20))\n",
    "fig.patch.set_facecolor('white')\n",
    "# plot best fit for each luminosity correlation\n",
    "for i, correlation in enumerate(correlations):\n",
    "\n",
    "    luminosities = correlations[correlation]['features']\n",
    "\n",
    "    # create empty figures with no axis\n",
    "    #plt.figure(figsize=(15,5))\n",
    "\n",
    "    #plt.subplot(121)\n",
    "\n",
    "    for GRB_sample, sample_type, color in zip(GRB_samples, sample_types, colors):\n",
    "        \n",
    "        df = GRB_sample.filter(luminosities).dropna()\n",
    "            \n",
    "        x = df[luminosities[0]].to_numpy()\n",
    "        y = df[luminosities[1]].to_numpy()\n",
    "        xerr = df[luminosities[2]].to_numpy()\n",
    "        yerr = df[luminosities[3]].to_numpy()\n",
    "\n",
    "        if sample_type != 'All-z':\n",
    "            axs[int(i/2), i%2].errorbar(x,y,xerr=xerr,yerr=yerr,fmt='.', ecolor=color, label=sample_type)\n",
    "        \n",
    "        axs[int(i/2), i%2].plot(\n",
    "            np.linspace(-2,2,100), \n",
    "            BestFitParameters[correlation][sample_type]['a'] + BestFitParameters[correlation][sample_type]['b'] * np.linspace(-2,2,100),\n",
    "            #luminosity_correlation_fit(np.linspace(-2,2,100), 'T_lag-L', sample_type), \n",
    "            linestyle='-', color=color, label=sample_type +' best fit'\n",
    "            )\n",
    "\n",
    "    axs[int(i/2), i%2].set_title(correlation)\n",
    "    axs[int(i/2), i%2].set_xlabel(luminosities[0])\n",
    "    axs[int(i/2), i%2].set_ylabel(luminosities[1])\n",
    "    axs[int(i/2), i%2].set_ylim(correlations[correlation]['ylim'])\n",
    "    axs[int(i/2), i%2].set_xlim(correlations[correlation]['xlim'])\n",
    "        \n",
    "    axs[int(i/2), i%2].legend()\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBPxbyPg8JzE"
   },
   "outputs": [],
   "source": [
    "# E_peak -> E_gamma -> E_iso -> d_L\n",
    "\n",
    "def caliberate_d_L(log_E_peak_i, log_E_peak_i_err, F_beam, F_beam_err, S_bolo, S_bolo_err, z):\n",
    "\n",
    "    def calculate_E_gamma_from_correlation(log_E_peak_i, log_E_peak_i_err):\n",
    "\n",
    "        # get best fit parameters for correlation\n",
    "        a = BestFitParameters['E_peak-E_gamma']['All-z']['a']\n",
    "        a_err = BestFitParameters['E_peak-E_gamma']['All-z']['a_err']\n",
    "        b = BestFitParameters['E_peak-E_gamma']['All-z']['b']\n",
    "        b_err = BestFitParameters['E_peak-E_gamma']['All-z']['b_err']\n",
    "\n",
    "        # log transformed, normalized E_peak\n",
    "        log_E_gamma = a + b * log_E_peak_i\n",
    "        log_E_gamma_err = np.sqrt(a_err**2 + (abs(b * log_E_peak_i) * np.sqrt((b_err/b)**2 + (log_E_peak_i_err/log_E_peak_i)**2))**2)\n",
    "\n",
    "        E_gamma = 10 ** log_E_gamma\n",
    "\n",
    "        E_gamma_err = abs(E_gamma) * abs(np.log(10) * log_E_gamma_err)\n",
    "\n",
    "        return E_gamma, E_gamma_err\n",
    "\n",
    "    def calculate_E_iso(E_gamma, E_gamma_err, F_beam, F_beam_err):\n",
    "\n",
    "        E_iso = E_gamma / F_beam\n",
    "        E_iso_err = abs(E_iso) * np.sqrt( (E_gamma_err/E_gamma)**2 + (F_beam_err/F_beam)**2 )\n",
    "\n",
    "        return E_iso, E_iso_err\n",
    "    \n",
    "\n",
    "    def calculate_d_L(E_iso, E_iso_err, S_bolo, S_bolo_err, z):\n",
    "\n",
    "        # calculate d_L\n",
    "        a = E_iso * (1. + z)\n",
    "        a_err = (1.+z) * E_iso_err\n",
    "\n",
    "        b = 4. * np.pi * S_bolo\n",
    "        b_err = 4. * np.pi * S_bolo_err\n",
    "\n",
    "        c = a/b\n",
    "        c_err = abs(c) * np.sqrt((a_err/a)**2 + (b_err/b)**2)\n",
    "\n",
    "        d_L = np.sqrt(c) \n",
    "        d_L_err = c_err / (2*np.sqrt(c))\n",
    "    \n",
    "        return d_L, d_L_err\n",
    "    \n",
    "    # calculate E_gamma from E_gamma-E_peak correlation\n",
    "    E_gamma, E_gamma_err = calculate_E_gamma_from_correlation(log_E_peak_i, log_E_peak_i_err)\n",
    "\n",
    "    # calculate E_iso\n",
    "    E_iso, E_iso_err = calculate_E_iso(E_gamma, E_gamma_err, F_beam, F_beam_err)\n",
    "\n",
    "    # calculate d_L\n",
    "    d_L, d_L_err = calculate_d_L(E_iso, E_iso_err, S_bolo, S_bolo_err, z)\n",
    "\n",
    "    return d_L, d_L_err\n",
    "\n",
    "def caliberate_mu(d_L, d_L_err):\n",
    "\n",
    "    # calculate mu\n",
    "    mu = 5. * np.log10(d_L / (10**6 * 3.086e+18)) + 25.\n",
    "    mu_err = abs(5. * d_L_err / (d_L * np.log(10))) \n",
    "\n",
    "    return mu, mu_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2eZiBWLiJW_"
   },
   "outputs": [],
   "source": [
    "# caliberate d_L from E_peak - E_gamma relation, hence only those GRBs with \n",
    "# sufficient data(E_peak, F_beam, S_bolo) can be caliberated using from this \n",
    "filtered_GRB = GRB[['E_gamma', 'E_gamma_err','log_E_peak_i', 'log_E_peak_i_err', 'F_beam', 'F_beam_err', 'S_bolo', 'S_bolo_err', 'z']].dropna()\n",
    "\n",
    "d_L, d_L_err = caliberate_d_L(\n",
    "    filtered_GRB['log_E_peak_i'].to_numpy(), \n",
    "    filtered_GRB['log_E_peak_i_err'].to_numpy(),\n",
    "    filtered_GRB['F_beam'].to_numpy(),\n",
    "    filtered_GRB['F_beam_err'].to_numpy(),\n",
    "    filtered_GRB['S_bolo'].to_numpy(),\n",
    "    filtered_GRB['S_bolo_err'].to_numpy(),\n",
    "    filtered_GRB['z'].to_numpy())\n",
    "\n",
    "mu_GRB, mu_err_GRB = caliberate_mu(d_L, d_L_err)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "ax.errorbar(filtered_GRB['z'].to_numpy(), mu_GRB, yerr=mu_err_GRB, fmt='.', color='b', capsize=2, label='GRB')\n",
    "ax.errorbar(data1['zCMB'], data1['MU'], yerr=data1['MUERR'], fmt='.r', capsize=2, label='Pantheon sample')\n",
    "ax.legend()\n",
    "ax.set_xlabel('z')\n",
    "ax.set_ylabel('mu')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "01-.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
