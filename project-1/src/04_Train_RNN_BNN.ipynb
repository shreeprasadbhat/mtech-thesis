{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 08:34:22.374142: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-21 08:34:23.218488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 17373 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2022-06-21 08:34:23.219786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22302 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "%run 03_Model_RNN_BNN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1QB73FpeuaIn"
   },
   "outputs": [],
   "source": [
    "# prepare data generators using tf.data\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((z_train, mu_train))\n",
    "    #.shuffle(TRAIN_LENGTH, reshuffle_each_iteration=True)\n",
    "    .batch(BATCH_SIZE, drop_remainder=False)\n",
    ");\n",
    "\n",
    "#test_dataset = tf.data.Dataset.from_tensor_slices((z_test,mu_test)).batch(BATCH_SIZE);\n",
    "val_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((z_val,mu_val))\n",
    "    .batch(BATCH_SIZE, drop_remainder=False)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "XyvUcghbN8qH"
   },
   "outputs": [],
   "source": [
    "model = my_model(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8HG_PcTwa8hf"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-3), \n",
    "    loss = tf.keras.losses.MeanSquaredError(), \n",
    "    metrics = tf.keras.metrics.RootMeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OwkIVKJgdwfo",
    "outputId": "b996fbeb-5a38-467c-d3c5-b81d2c581e60",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/8 [==>...........................] - ETA: 17s - loss: 0.8706 - root_mean_squared_error: 0.9331\n",
      "Epoch 00001: val_loss improved from inf to 0.88176, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 3s 105ms/step - loss: 1.0229 - root_mean_squared_error: 1.0114 - val_loss: 0.8818 - val_root_mean_squared_error: 0.9390\n",
      "Epoch 2/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7868 - root_mean_squared_error: 0.8870\n",
      "Epoch 00002: val_loss improved from 0.88176 to 0.76375, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9078 - root_mean_squared_error: 0.9528 - val_loss: 0.7638 - val_root_mean_squared_error: 0.8739\n",
      "Epoch 3/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6849 - root_mean_squared_error: 0.8276\n",
      "Epoch 00003: val_loss improved from 0.76375 to 0.66833, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7688 - root_mean_squared_error: 0.8768 - val_loss: 0.6683 - val_root_mean_squared_error: 0.8175\n",
      "Epoch 4/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.7020 - root_mean_squared_error: 0.8379\n",
      "Epoch 00004: val_loss improved from 0.66833 to 0.56550, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6845 - root_mean_squared_error: 0.8274 - val_loss: 0.5655 - val_root_mean_squared_error: 0.7520\n",
      "Epoch 5/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.4765 - root_mean_squared_error: 0.6903\n",
      "Epoch 00005: val_loss improved from 0.56550 to 0.51267, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5952 - root_mean_squared_error: 0.7715 - val_loss: 0.5127 - val_root_mean_squared_error: 0.7160\n",
      "Epoch 6/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.4270 - root_mean_squared_error: 0.6534\n",
      "Epoch 00006: val_loss improved from 0.51267 to 0.46999, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5356 - root_mean_squared_error: 0.7318 - val_loss: 0.4700 - val_root_mean_squared_error: 0.6856\n",
      "Epoch 7/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.4044 - root_mean_squared_error: 0.6359\n",
      "Epoch 00007: val_loss improved from 0.46999 to 0.41897, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4853 - root_mean_squared_error: 0.6966 - val_loss: 0.4190 - val_root_mean_squared_error: 0.6473\n",
      "Epoch 8/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.3683 - root_mean_squared_error: 0.6069\n",
      "Epoch 00008: val_loss improved from 0.41897 to 0.37463, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4345 - root_mean_squared_error: 0.6592 - val_loss: 0.3746 - val_root_mean_squared_error: 0.6121\n",
      "Epoch 9/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.3329 - root_mean_squared_error: 0.5770\n",
      "Epoch 00009: val_loss improved from 0.37463 to 0.34064, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3876 - root_mean_squared_error: 0.6226 - val_loss: 0.3406 - val_root_mean_squared_error: 0.5836\n",
      "Epoch 10/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.3071 - root_mean_squared_error: 0.5541\n",
      "Epoch 00010: val_loss improved from 0.34064 to 0.30819, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3507 - root_mean_squared_error: 0.5922 - val_loss: 0.3082 - val_root_mean_squared_error: 0.5552\n",
      "Epoch 11/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.2785 - root_mean_squared_error: 0.5277\n",
      "Epoch 00011: val_loss improved from 0.30819 to 0.27899, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3196 - root_mean_squared_error: 0.5653 - val_loss: 0.2790 - val_root_mean_squared_error: 0.5282\n",
      "Epoch 12/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.2528 - root_mean_squared_error: 0.5028\n",
      "Epoch 00012: val_loss improved from 0.27899 to 0.25189, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2898 - root_mean_squared_error: 0.5384 - val_loss: 0.2519 - val_root_mean_squared_error: 0.5019\n",
      "Epoch 13/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.2298 - root_mean_squared_error: 0.4794\n",
      "Epoch 00013: val_loss improved from 0.25189 to 0.22407, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2617 - root_mean_squared_error: 0.5115 - val_loss: 0.2241 - val_root_mean_squared_error: 0.4734\n",
      "Epoch 14/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.2063 - root_mean_squared_error: 0.4542\n",
      "Epoch 00014: val_loss improved from 0.22407 to 0.19757, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2331 - root_mean_squared_error: 0.4828 - val_loss: 0.1976 - val_root_mean_squared_error: 0.4445\n",
      "Epoch 15/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1849 - root_mean_squared_error: 0.4300\n",
      "Epoch 00015: val_loss improved from 0.19757 to 0.17303, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2054 - root_mean_squared_error: 0.4533 - val_loss: 0.1730 - val_root_mean_squared_error: 0.4160\n",
      "Epoch 16/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1656 - root_mean_squared_error: 0.4070\n",
      "Epoch 00016: val_loss improved from 0.17303 to 0.15556, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1810 - root_mean_squared_error: 0.4255 - val_loss: 0.1556 - val_root_mean_squared_error: 0.3944\n",
      "Epoch 17/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1536 - root_mean_squared_error: 0.3919\n",
      "Epoch 00017: val_loss improved from 0.15556 to 0.14539, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1638 - root_mean_squared_error: 0.4048 - val_loss: 0.1454 - val_root_mean_squared_error: 0.3813\n",
      "Epoch 18/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1478 - root_mean_squared_error: 0.3845\n",
      "Epoch 00018: val_loss improved from 0.14539 to 0.13703, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1529 - root_mean_squared_error: 0.3911 - val_loss: 0.1370 - val_root_mean_squared_error: 0.3702\n",
      "Epoch 19/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1418 - root_mean_squared_error: 0.3766\n",
      "Epoch 00019: val_loss improved from 0.13703 to 0.12737, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1438 - root_mean_squared_error: 0.3792 - val_loss: 0.1274 - val_root_mean_squared_error: 0.3569\n",
      "Epoch 20/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1328 - root_mean_squared_error: 0.3644\n",
      "Epoch 00020: val_loss improved from 0.12737 to 0.11854, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1350 - root_mean_squared_error: 0.3674 - val_loss: 0.1185 - val_root_mean_squared_error: 0.3443\n",
      "Epoch 21/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1242 - root_mean_squared_error: 0.3524\n",
      "Epoch 00021: val_loss improved from 0.11854 to 0.11111, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1271 - root_mean_squared_error: 0.3565 - val_loss: 0.1111 - val_root_mean_squared_error: 0.3333\n",
      "Epoch 22/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1171 - root_mean_squared_error: 0.3422\n",
      "Epoch 00022: val_loss improved from 0.11111 to 0.10444, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1199 - root_mean_squared_error: 0.3463 - val_loss: 0.1044 - val_root_mean_squared_error: 0.3232\n",
      "Epoch 23/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1109 - root_mean_squared_error: 0.3330\n",
      "Epoch 00023: val_loss improved from 0.10444 to 0.09840, saving model to ../out/union/lstm/cp.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1132 - root_mean_squared_error: 0.3365 - val_loss: 0.0984 - val_root_mean_squared_error: 0.3137\n",
      "Epoch 24/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1053 - root_mean_squared_error: 0.3244\n",
      "Epoch 00024: val_loss improved from 0.09840 to 0.09270, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1070 - root_mean_squared_error: 0.3271 - val_loss: 0.0927 - val_root_mean_squared_error: 0.3045\n",
      "Epoch 25/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0999 - root_mean_squared_error: 0.3161\n",
      "Epoch 00025: val_loss improved from 0.09270 to 0.08733, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1012 - root_mean_squared_error: 0.3182 - val_loss: 0.0873 - val_root_mean_squared_error: 0.2955\n",
      "Epoch 26/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0948 - root_mean_squared_error: 0.3079\n",
      "Epoch 00026: val_loss improved from 0.08733 to 0.08235, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0958 - root_mean_squared_error: 0.3096 - val_loss: 0.0824 - val_root_mean_squared_error: 0.2870\n",
      "Epoch 27/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0901 - root_mean_squared_error: 0.3001\n",
      "Epoch 00027: val_loss improved from 0.08235 to 0.07775, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0908 - root_mean_squared_error: 0.3014 - val_loss: 0.0777 - val_root_mean_squared_error: 0.2788\n",
      "Epoch 28/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0857 - root_mean_squared_error: 0.2928\n",
      "Epoch 00028: val_loss improved from 0.07775 to 0.07353, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0735 - val_root_mean_squared_error: 0.2712\n",
      "Epoch 29/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0818 - root_mean_squared_error: 0.2860\n",
      "Epoch 00029: val_loss improved from 0.07353 to 0.06966, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0818 - root_mean_squared_error: 0.2861 - val_loss: 0.0697 - val_root_mean_squared_error: 0.2639\n",
      "Epoch 30/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0782 - root_mean_squared_error: 0.2797\n",
      "Epoch 00030: val_loss improved from 0.06966 to 0.06608, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0778 - root_mean_squared_error: 0.2790 - val_loss: 0.0661 - val_root_mean_squared_error: 0.2571\n",
      "Epoch 31/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0750 - root_mean_squared_error: 0.2738\n",
      "Epoch 00031: val_loss improved from 0.06608 to 0.06278, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0741 - root_mean_squared_error: 0.2721 - val_loss: 0.0628 - val_root_mean_squared_error: 0.2506\n",
      "Epoch 32/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0720 - root_mean_squared_error: 0.2683\n",
      "Epoch 00032: val_loss improved from 0.06278 to 0.05973, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0706 - root_mean_squared_error: 0.2656 - val_loss: 0.0597 - val_root_mean_squared_error: 0.2444\n",
      "Epoch 33/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0693 - root_mean_squared_error: 0.2633\n",
      "Epoch 00033: val_loss improved from 0.05973 to 0.05692, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0673 - root_mean_squared_error: 0.2594 - val_loss: 0.0569 - val_root_mean_squared_error: 0.2386\n",
      "Epoch 34/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0669 - root_mean_squared_error: 0.2586\n",
      "Epoch 00034: val_loss improved from 0.05692 to 0.05433, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0642 - root_mean_squared_error: 0.2534 - val_loss: 0.0543 - val_root_mean_squared_error: 0.2331\n",
      "Epoch 35/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0647 - root_mean_squared_error: 0.2544\n",
      "Epoch 00035: val_loss improved from 0.05433 to 0.05196, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0614 - root_mean_squared_error: 0.2477 - val_loss: 0.0520 - val_root_mean_squared_error: 0.2279\n",
      "Epoch 36/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0628 - root_mean_squared_error: 0.2505\n",
      "Epoch 00036: val_loss improved from 0.05196 to 0.04978, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0587 - root_mean_squared_error: 0.2423 - val_loss: 0.0498 - val_root_mean_squared_error: 0.2231\n",
      "Epoch 37/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0610 - root_mean_squared_error: 0.2471\n",
      "Epoch 00037: val_loss improved from 0.04978 to 0.04779, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0562 - root_mean_squared_error: 0.2371 - val_loss: 0.0478 - val_root_mean_squared_error: 0.2186\n",
      "Epoch 38/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0595 - root_mean_squared_error: 0.2439\n",
      "Epoch 00038: val_loss improved from 0.04779 to 0.04595, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0539 - root_mean_squared_error: 0.2322 - val_loss: 0.0460 - val_root_mean_squared_error: 0.2144\n",
      "Epoch 39/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0581 - root_mean_squared_error: 0.2410\n",
      "Epoch 00039: val_loss improved from 0.04595 to 0.04426, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0518 - root_mean_squared_error: 0.2275 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2104\n",
      "Epoch 40/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0568 - root_mean_squared_error: 0.2383\n",
      "Epoch 00040: val_loss improved from 0.04426 to 0.04268, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2066\n",
      "Epoch 41/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0556 - root_mean_squared_error: 0.2357\n",
      "Epoch 00041: val_loss improved from 0.04268 to 0.04119, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0479 - root_mean_squared_error: 0.2188 - val_loss: 0.0412 - val_root_mean_squared_error: 0.2030\n",
      "Epoch 42/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0544 - root_mean_squared_error: 0.2332\n",
      "Epoch 00042: val_loss improved from 0.04119 to 0.03979, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0461 - root_mean_squared_error: 0.2148 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1995\n",
      "Epoch 43/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0532 - root_mean_squared_error: 0.2308\n",
      "Epoch 00043: val_loss improved from 0.03979 to 0.03844, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0444 - root_mean_squared_error: 0.2108 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1961\n",
      "Epoch 44/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0521 - root_mean_squared_error: 0.2283\n",
      "Epoch 00044: val_loss improved from 0.03844 to 0.03715, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0428 - root_mean_squared_error: 0.2070 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1927\n",
      "Epoch 45/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0510 - root_mean_squared_error: 0.2258\n",
      "Epoch 00045: val_loss improved from 0.03715 to 0.03590, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0413 - root_mean_squared_error: 0.2032 - val_loss: 0.0359 - val_root_mean_squared_error: 0.1895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0499 - root_mean_squared_error: 0.2233\n",
      "Epoch 00046: val_loss improved from 0.03590 to 0.03470, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0398 - root_mean_squared_error: 0.1996 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1863\n",
      "Epoch 47/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0487 - root_mean_squared_error: 0.2208\n",
      "Epoch 00047: val_loss improved from 0.03470 to 0.03354, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0384 - root_mean_squared_error: 0.1960 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1831\n",
      "Epoch 48/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0476 - root_mean_squared_error: 0.2182\n",
      "Epoch 00048: val_loss improved from 0.03354 to 0.03241, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0371 - root_mean_squared_error: 0.1925 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1800\n",
      "Epoch 49/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0465 - root_mean_squared_error: 0.2156\n",
      "Epoch 00049: val_loss improved from 0.03241 to 0.03134, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0358 - root_mean_squared_error: 0.1891 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1770\n",
      "Epoch 50/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0454 - root_mean_squared_error: 0.2131\n",
      "Epoch 00050: val_loss improved from 0.03134 to 0.03030, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0345 - root_mean_squared_error: 0.1858 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 51/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0443 - root_mean_squared_error: 0.2105\n",
      "Epoch 00051: val_loss improved from 0.03030 to 0.02932, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0333 - root_mean_squared_error: 0.1826 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1712\n",
      "Epoch 52/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0433 - root_mean_squared_error: 0.2080\n",
      "Epoch 00052: val_loss improved from 0.02932 to 0.02838, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1685\n",
      "Epoch 53/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0422 - root_mean_squared_error: 0.2055\n",
      "Epoch 00053: val_loss improved from 0.02838 to 0.02750, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0311 - root_mean_squared_error: 0.1765 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1658\n",
      "Epoch 54/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0412 - root_mean_squared_error: 0.2031\n",
      "Epoch 00054: val_loss improved from 0.02750 to 0.02667, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0301 - root_mean_squared_error: 0.1736 - val_loss: 0.0267 - val_root_mean_squared_error: 0.1633\n",
      "Epoch 55/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0403 - root_mean_squared_error: 0.2008\n",
      "Epoch 00055: val_loss improved from 0.02667 to 0.02591, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0292 - root_mean_squared_error: 0.1709 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1610\n",
      "Epoch 56/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0394 - root_mean_squared_error: 0.1985\n",
      "Epoch 00056: val_loss improved from 0.02591 to 0.02521, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0283 - root_mean_squared_error: 0.1683 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1588\n",
      "Epoch 57/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0386 - root_mean_squared_error: 0.1963\n",
      "Epoch 00057: val_loss improved from 0.02521 to 0.02457, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0275 - root_mean_squared_error: 0.1659 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1567\n",
      "Epoch 58/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0377 - root_mean_squared_error: 0.1943\n",
      "Epoch 00058: val_loss improved from 0.02457 to 0.02399, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0268 - root_mean_squared_error: 0.1636 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1549\n",
      "Epoch 59/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0370 - root_mean_squared_error: 0.1923\n",
      "Epoch 00059: val_loss improved from 0.02399 to 0.02347, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0261 - root_mean_squared_error: 0.1616 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 60/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0363 - root_mean_squared_error: 0.1904\n",
      "Epoch 00060: val_loss improved from 0.02347 to 0.02300, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0255 - root_mean_squared_error: 0.1597 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1517\n",
      "Epoch 61/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0356 - root_mean_squared_error: 0.1886\n",
      "Epoch 00061: val_loss improved from 0.02300 to 0.02258, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0250 - root_mean_squared_error: 0.1580 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1503\n",
      "Epoch 62/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0349 - root_mean_squared_error: 0.1868\n",
      "Epoch 00062: val_loss improved from 0.02258 to 0.02220, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0245 - root_mean_squared_error: 0.1564 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1490\n",
      "Epoch 63/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0343 - root_mean_squared_error: 0.1851\n",
      "Epoch 00063: val_loss improved from 0.02220 to 0.02184, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0240 - root_mean_squared_error: 0.1550 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1478\n",
      "Epoch 64/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0337 - root_mean_squared_error: 0.1835\n",
      "Epoch 00064: val_loss improved from 0.02184 to 0.02152, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0236 - root_mean_squared_error: 0.1537 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1467\n",
      "Epoch 65/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0331 - root_mean_squared_error: 0.1819\n",
      "Epoch 00065: val_loss improved from 0.02152 to 0.02122, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0233 - root_mean_squared_error: 0.1525 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1457\n",
      "Epoch 66/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0325 - root_mean_squared_error: 0.1804\n",
      "Epoch 00066: val_loss improved from 0.02122 to 0.02094, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0229 - root_mean_squared_error: 0.1514 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1447\n",
      "Epoch 67/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0320 - root_mean_squared_error: 0.1789\n",
      "Epoch 00067: val_loss improved from 0.02094 to 0.02069, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0226 - root_mean_squared_error: 0.1504 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1438\n",
      "Epoch 68/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0315 - root_mean_squared_error: 0.1775\n",
      "Epoch 00068: val_loss improved from 0.02069 to 0.02044, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0311 - root_mean_squared_error: 0.1762\n",
      "Epoch 00069: val_loss improved from 0.02044 to 0.02021, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0220 - root_mean_squared_error: 0.1485 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1422\n",
      "Epoch 70/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0306 - root_mean_squared_error: 0.1750\n",
      "Epoch 00070: val_loss improved from 0.02021 to 0.02000, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0218 - root_mean_squared_error: 0.1476 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1414\n",
      "Epoch 71/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0302 - root_mean_squared_error: 0.1738\n",
      "Epoch 00071: val_loss improved from 0.02000 to 0.01979, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0215 - root_mean_squared_error: 0.1468 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1407\n",
      "Epoch 72/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0298 - root_mean_squared_error: 0.1727\n",
      "Epoch 00072: val_loss improved from 0.01979 to 0.01960, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0213 - root_mean_squared_error: 0.1460 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1400\n",
      "Epoch 73/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0294 - root_mean_squared_error: 0.1716\n",
      "Epoch 00073: val_loss improved from 0.01960 to 0.01941, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0211 - root_mean_squared_error: 0.1453 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1393\n",
      "Epoch 74/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0291 - root_mean_squared_error: 0.1706\n",
      "Epoch 00074: val_loss improved from 0.01941 to 0.01923, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0209 - root_mean_squared_error: 0.1445 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1387\n",
      "Epoch 75/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0288 - root_mean_squared_error: 0.1696\n",
      "Epoch 00075: val_loss improved from 0.01923 to 0.01905, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0207 - root_mean_squared_error: 0.1438 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1380\n",
      "Epoch 76/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0285 - root_mean_squared_error: 0.1687\n",
      "Epoch 00076: val_loss improved from 0.01905 to 0.01888, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0205 - root_mean_squared_error: 0.1432 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1374\n",
      "Epoch 77/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0282 - root_mean_squared_error: 0.1678\n",
      "Epoch 00077: val_loss improved from 0.01888 to 0.01872, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0203 - root_mean_squared_error: 0.1425 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 78/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0205 - root_mean_squared_error: 0.1433\n",
      "Epoch 00078: val_loss improved from 0.01872 to 0.01856, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0201 - root_mean_squared_error: 0.1419 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1362\n",
      "Epoch 79/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0276 - root_mean_squared_error: 0.1661\n",
      "Epoch 00079: val_loss improved from 0.01856 to 0.01840, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0199 - root_mean_squared_error: 0.1412 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1357\n",
      "Epoch 80/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0273 - root_mean_squared_error: 0.1653\n",
      "Epoch 00080: val_loss improved from 0.01840 to 0.01825, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0198 - root_mean_squared_error: 0.1406 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1351\n",
      "Epoch 81/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0271 - root_mean_squared_error: 0.1646\n",
      "Epoch 00081: val_loss improved from 0.01825 to 0.01810, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1345\n",
      "Epoch 82/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0268 - root_mean_squared_error: 0.1638\n",
      "Epoch 00082: val_loss improved from 0.01810 to 0.01795, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1340\n",
      "Epoch 83/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0266 - root_mean_squared_error: 0.1631\n",
      "Epoch 00083: val_loss improved from 0.01795 to 0.01780, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0193 - root_mean_squared_error: 0.1388 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1334\n",
      "Epoch 84/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0264 - root_mean_squared_error: 0.1624\n",
      "Epoch 00084: val_loss improved from 0.01780 to 0.01766, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0191 - root_mean_squared_error: 0.1382 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1329\n",
      "Epoch 85/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0262 - root_mean_squared_error: 0.1617\n",
      "Epoch 00085: val_loss improved from 0.01766 to 0.01752, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0189 - root_mean_squared_error: 0.1376 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1324\n",
      "Epoch 86/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0259 - root_mean_squared_error: 0.1611\n",
      "Epoch 00086: val_loss improved from 0.01752 to 0.01738, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0188 - root_mean_squared_error: 0.1371 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1318\n",
      "Epoch 87/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0257 - root_mean_squared_error: 0.1604\n",
      "Epoch 00087: val_loss improved from 0.01738 to 0.01724, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0186 - root_mean_squared_error: 0.1365 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1313\n",
      "Epoch 88/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0255 - root_mean_squared_error: 0.1598\n",
      "Epoch 00088: val_loss improved from 0.01724 to 0.01711, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1308\n",
      "Epoch 89/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0253 - root_mean_squared_error: 0.1592\n",
      "Epoch 00089: val_loss improved from 0.01711 to 0.01697, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1303\n",
      "Epoch 90/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0251 - root_mean_squared_error: 0.1586\n",
      "Epoch 00090: val_loss improved from 0.01697 to 0.01684, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0182 - root_mean_squared_error: 0.1348 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1298\n",
      "Epoch 91/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0250 - root_mean_squared_error: 0.1580\n",
      "Epoch 00091: val_loss improved from 0.01684 to 0.01671, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0180 - root_mean_squared_error: 0.1343 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0248 - root_mean_squared_error: 0.1574\n",
      "Epoch 00092: val_loss improved from 0.01671 to 0.01658, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0179 - root_mean_squared_error: 0.1337 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1288\n",
      "Epoch 93/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0246 - root_mean_squared_error: 0.1568\n",
      "Epoch 00093: val_loss improved from 0.01658 to 0.01645, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0177 - root_mean_squared_error: 0.1332 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1283\n",
      "Epoch 94/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0244 - root_mean_squared_error: 0.1563\n",
      "Epoch 00094: val_loss improved from 0.01645 to 0.01633, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0176 - root_mean_squared_error: 0.1327 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1278\n",
      "Epoch 95/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0242 - root_mean_squared_error: 0.1557\n",
      "Epoch 00095: val_loss improved from 0.01633 to 0.01620, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0175 - root_mean_squared_error: 0.1321 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1273\n",
      "Epoch 96/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0241 - root_mean_squared_error: 0.1551\n",
      "Epoch 00096: val_loss improved from 0.01620 to 0.01608, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 97/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0239 - root_mean_squared_error: 0.1546\n",
      "Epoch 00097: val_loss improved from 0.01608 to 0.01595, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0172 - root_mean_squared_error: 0.1311 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1263\n",
      "Epoch 98/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0237 - root_mean_squared_error: 0.1540\n",
      "Epoch 00098: val_loss improved from 0.01595 to 0.01583, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0170 - root_mean_squared_error: 0.1305 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1258\n",
      "Epoch 99/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0236 - root_mean_squared_error: 0.1535\n",
      "Epoch 00099: val_loss improved from 0.01583 to 0.01571, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0169 - root_mean_squared_error: 0.1300 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 100/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0234 - root_mean_squared_error: 0.1530\n",
      "Epoch 00100: val_loss improved from 0.01571 to 0.01559, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0168 - root_mean_squared_error: 0.1295 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1249\n",
      "Epoch 101/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0232 - root_mean_squared_error: 0.1524\n",
      "Epoch 00101: val_loss improved from 0.01559 to 0.01547, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1244\n",
      "Epoch 102/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0231 - root_mean_squared_error: 0.1519\n",
      "Epoch 00102: val_loss improved from 0.01547 to 0.01535, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0165 - root_mean_squared_error: 0.1284 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1239\n",
      "Epoch 103/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0229 - root_mean_squared_error: 0.1514\n",
      "Epoch 00103: val_loss improved from 0.01535 to 0.01523, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0164 - root_mean_squared_error: 0.1279 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1234\n",
      "Epoch 104/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0228 - root_mean_squared_error: 0.1508\n",
      "Epoch 00104: val_loss improved from 0.01523 to 0.01512, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0162 - root_mean_squared_error: 0.1274 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1229\n",
      "Epoch 105/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0226 - root_mean_squared_error: 0.1503\n",
      "Epoch 00105: val_loss improved from 0.01512 to 0.01500, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0161 - root_mean_squared_error: 0.1269 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 106/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0224 - root_mean_squared_error: 0.1498\n",
      "Epoch 00106: val_loss improved from 0.01500 to 0.01489, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0160 - root_mean_squared_error: 0.1264 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220\n",
      "Epoch 107/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0223 - root_mean_squared_error: 0.1493\n",
      "Epoch 00107: val_loss improved from 0.01489 to 0.01477, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0158 - root_mean_squared_error: 0.1259 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1215\n",
      "Epoch 108/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0221 - root_mean_squared_error: 0.1487\n",
      "Epoch 00108: val_loss improved from 0.01477 to 0.01466, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0157 - root_mean_squared_error: 0.1254 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1211\n",
      "Epoch 109/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0220 - root_mean_squared_error: 0.1482\n",
      "Epoch 00109: val_loss improved from 0.01466 to 0.01455, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 110/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0218 - root_mean_squared_error: 0.1477\n",
      "Epoch 00110: val_loss improved from 0.01455 to 0.01443, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0155 - root_mean_squared_error: 0.1244 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1201\n",
      "Epoch 111/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0217 - root_mean_squared_error: 0.1472\n",
      "Epoch 00111: val_loss improved from 0.01443 to 0.01432, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0153 - root_mean_squared_error: 0.1239 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1197\n",
      "Epoch 112/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0215 - root_mean_squared_error: 0.1467\n",
      "Epoch 00112: val_loss improved from 0.01432 to 0.01421, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0152 - root_mean_squared_error: 0.1234 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 113/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0214 - root_mean_squared_error: 0.1461\n",
      "Epoch 00113: val_loss improved from 0.01421 to 0.01410, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0151 - root_mean_squared_error: 0.1229 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1188\n",
      "Epoch 114/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0212 - root_mean_squared_error: 0.1456\n",
      "Epoch 00114: val_loss improved from 0.01410 to 0.01400, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0150 - root_mean_squared_error: 0.1224 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0211 - root_mean_squared_error: 0.1451\n",
      "Epoch 00115: val_loss improved from 0.01400 to 0.01389, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0149 - root_mean_squared_error: 0.1219 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 116/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0209 - root_mean_squared_error: 0.1446\n",
      "Epoch 00116: val_loss improved from 0.01389 to 0.01378, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0147 - root_mean_squared_error: 0.1214 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 117/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0208 - root_mean_squared_error: 0.1441\n",
      "Epoch 00117: val_loss improved from 0.01378 to 0.01367, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0146 - root_mean_squared_error: 0.1209 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 118/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0206 - root_mean_squared_error: 0.1435\n",
      "Epoch 00118: val_loss improved from 0.01367 to 0.01357, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0145 - root_mean_squared_error: 0.1204 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165\n",
      "Epoch 119/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0205 - root_mean_squared_error: 0.1430\n",
      "Epoch 00119: val_loss improved from 0.01357 to 0.01347, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0144 - root_mean_squared_error: 0.1199 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1160\n",
      "Epoch 120/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0203 - root_mean_squared_error: 0.1425\n",
      "Epoch 00120: val_loss improved from 0.01347 to 0.01336, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0143 - root_mean_squared_error: 0.1195 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1156\n",
      "Epoch 121/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0202 - root_mean_squared_error: 0.1420\n",
      "Epoch 00121: val_loss improved from 0.01336 to 0.01326, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0142 - root_mean_squared_error: 0.1190 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1151\n",
      "Epoch 122/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0200 - root_mean_squared_error: 0.1414\n",
      "Epoch 00122: val_loss improved from 0.01326 to 0.01316, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0140 - root_mean_squared_error: 0.1185 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1147\n",
      "Epoch 123/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0199 - root_mean_squared_error: 0.1409\n",
      "Epoch 00123: val_loss improved from 0.01316 to 0.01306, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0139 - root_mean_squared_error: 0.1180 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1143\n",
      "Epoch 124/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0197 - root_mean_squared_error: 0.1404\n",
      "Epoch 00124: val_loss improved from 0.01306 to 0.01296, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0138 - root_mean_squared_error: 0.1176 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1138\n",
      "Epoch 125/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0196 - root_mean_squared_error: 0.1399\n",
      "Epoch 00125: val_loss improved from 0.01296 to 0.01286, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0137 - root_mean_squared_error: 0.1171 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 126/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0194 - root_mean_squared_error: 0.1393\n",
      "Epoch 00126: val_loss improved from 0.01286 to 0.01276, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0136 - root_mean_squared_error: 0.1166 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1129\n",
      "Epoch 127/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0193 - root_mean_squared_error: 0.1388\n",
      "Epoch 00127: val_loss improved from 0.01276 to 0.01266, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0135 - root_mean_squared_error: 0.1162 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 128/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0191 - root_mean_squared_error: 0.1383\n",
      "Epoch 00128: val_loss improved from 0.01266 to 0.01256, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0134 - root_mean_squared_error: 0.1157 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 129/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0190 - root_mean_squared_error: 0.1378\n",
      "Epoch 00129: val_loss improved from 0.01256 to 0.01247, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0133 - root_mean_squared_error: 0.1153 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 130/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0188 - root_mean_squared_error: 0.1372\n",
      "Epoch 00130: val_loss improved from 0.01247 to 0.01237, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0132 - root_mean_squared_error: 0.1148 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1112\n",
      "Epoch 131/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0187 - root_mean_squared_error: 0.1367\n",
      "Epoch 00131: val_loss improved from 0.01237 to 0.01228, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0131 - root_mean_squared_error: 0.1144 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 132/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0185 - root_mean_squared_error: 0.1362\n",
      "Epoch 00132: val_loss improved from 0.01228 to 0.01219, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0130 - root_mean_squared_error: 0.1139 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1104\n",
      "Epoch 133/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0184 - root_mean_squared_error: 0.1357\n",
      "Epoch 00133: val_loss improved from 0.01219 to 0.01209, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0129 - root_mean_squared_error: 0.1135 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 134/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0183 - root_mean_squared_error: 0.1351\n",
      "Epoch 00134: val_loss improved from 0.01209 to 0.01200, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0128 - root_mean_squared_error: 0.1130 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 135/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0181 - root_mean_squared_error: 0.1346\n",
      "Epoch 00135: val_loss improved from 0.01200 to 0.01191, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0127 - root_mean_squared_error: 0.1126 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 136/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0180 - root_mean_squared_error: 0.1341\n",
      "Epoch 00136: val_loss improved from 0.01191 to 0.01182, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0126 - root_mean_squared_error: 0.1122 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 137/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0178 - root_mean_squared_error: 0.1335\n",
      "Epoch 00137: val_loss improved from 0.01182 to 0.01173, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0125 - root_mean_squared_error: 0.1117 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0177 - root_mean_squared_error: 0.1330\n",
      "Epoch 00138: val_loss improved from 0.01173 to 0.01165, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0124 - root_mean_squared_error: 0.1113 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 139/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0176 - root_mean_squared_error: 0.1325\n",
      "Epoch 00139: val_loss improved from 0.01165 to 0.01156, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 140/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0174 - root_mean_squared_error: 0.1320\n",
      "Epoch 00140: val_loss improved from 0.01156 to 0.01147, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0122 - root_mean_squared_error: 0.1105 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 141/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0173 - root_mean_squared_error: 0.1315\n",
      "Epoch 00141: val_loss improved from 0.01147 to 0.01139, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0121 - root_mean_squared_error: 0.1101 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 142/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0171 - root_mean_squared_error: 0.1309\n",
      "Epoch 00142: val_loss improved from 0.01139 to 0.01131, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0120 - root_mean_squared_error: 0.1097 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1063\n",
      "Epoch 143/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0170 - root_mean_squared_error: 0.1304\n",
      "Epoch 00143: val_loss improved from 0.01131 to 0.01123, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0119 - root_mean_squared_error: 0.1093 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060\n",
      "Epoch 144/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0169 - root_mean_squared_error: 0.1299\n",
      "Epoch 00144: val_loss improved from 0.01123 to 0.01114, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0119 - root_mean_squared_error: 0.1089 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1056\n",
      "Epoch 145/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0167 - root_mean_squared_error: 0.1294\n",
      "Epoch 00145: val_loss improved from 0.01114 to 0.01106, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0118 - root_mean_squared_error: 0.1085 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 146/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0166 - root_mean_squared_error: 0.1289\n",
      "Epoch 00146: val_loss improved from 0.01106 to 0.01099, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048\n",
      "Epoch 147/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0165 - root_mean_squared_error: 0.1284\n",
      "Epoch 00147: val_loss improved from 0.01099 to 0.01091, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0116 - root_mean_squared_error: 0.1078 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1044\n",
      "Epoch 148/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0164 - root_mean_squared_error: 0.1279\n",
      "Epoch 00148: val_loss improved from 0.01091 to 0.01083, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0115 - root_mean_squared_error: 0.1074 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 149/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0162 - root_mean_squared_error: 0.1274\n",
      "Epoch 00149: val_loss improved from 0.01083 to 0.01076, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0115 - root_mean_squared_error: 0.1070 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1037\n",
      "Epoch 150/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0161 - root_mean_squared_error: 0.1269\n",
      "Epoch 00150: val_loss improved from 0.01076 to 0.01068, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0114 - root_mean_squared_error: 0.1067 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 151/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0160 - root_mean_squared_error: 0.1264\n",
      "Epoch 00151: val_loss improved from 0.01068 to 0.01061, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 152/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0159 - root_mean_squared_error: 0.1259\n",
      "Epoch 00152: val_loss improved from 0.01061 to 0.01054, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0112 - root_mean_squared_error: 0.1060 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 153/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0157 - root_mean_squared_error: 0.1255\n",
      "Epoch 00153: val_loss improved from 0.01054 to 0.01047, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0112 - root_mean_squared_error: 0.1057 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 154/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0156 - root_mean_squared_error: 0.1250\n",
      "Epoch 00154: val_loss improved from 0.01047 to 0.01040, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0111 - root_mean_squared_error: 0.1053 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 155/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0155 - root_mean_squared_error: 0.1245\n",
      "Epoch 00155: val_loss improved from 0.01040 to 0.01034, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0110 - root_mean_squared_error: 0.1050 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 156/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0154 - root_mean_squared_error: 0.1240\n",
      "Epoch 00156: val_loss improved from 0.01034 to 0.01027, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0110 - root_mean_squared_error: 0.1047 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 157/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0153 - root_mean_squared_error: 0.1236\n",
      "Epoch 00157: val_loss improved from 0.01027 to 0.01021, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 158/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0152 - root_mean_squared_error: 0.1231\n",
      "Epoch 00158: val_loss improved from 0.01021 to 0.01015, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0108 - root_mean_squared_error: 0.1041 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 159/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0150 - root_mean_squared_error: 0.1227\n",
      "Epoch 00159: val_loss improved from 0.01015 to 0.01008, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0108 - root_mean_squared_error: 0.1038 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 160/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0149 - root_mean_squared_error: 0.1222\n",
      "Epoch 00160: val_loss improved from 0.01008 to 0.01003, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0107 - root_mean_squared_error: 0.1035 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0148 - root_mean_squared_error: 0.1218\n",
      "Epoch 00161: val_loss improved from 0.01003 to 0.00997, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0106 - root_mean_squared_error: 0.1032 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 162/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0147 - root_mean_squared_error: 0.1214\n",
      "Epoch 00162: val_loss improved from 0.00997 to 0.00991, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0106 - root_mean_squared_error: 0.1029 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0996\n",
      "Epoch 163/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0146 - root_mean_squared_error: 0.1209\n",
      "Epoch 00163: val_loss improved from 0.00991 to 0.00986, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0105 - root_mean_squared_error: 0.1026 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 164/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0145 - root_mean_squared_error: 0.1205\n",
      "Epoch 00164: val_loss improved from 0.00986 to 0.00980, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0105 - root_mean_squared_error: 0.1023 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990\n",
      "Epoch 165/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0144 - root_mean_squared_error: 0.1201\n",
      "Epoch 00165: val_loss improved from 0.00980 to 0.00975, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0104 - root_mean_squared_error: 0.1020 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 166/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0143 - root_mean_squared_error: 0.1197\n",
      "Epoch 00166: val_loss improved from 0.00975 to 0.00970, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0104 - root_mean_squared_error: 0.1018 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 167/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0142 - root_mean_squared_error: 0.1193\n",
      "Epoch 00167: val_loss improved from 0.00970 to 0.00965, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0103 - root_mean_squared_error: 0.1015 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0982\n",
      "Epoch 168/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0141 - root_mean_squared_error: 0.1189\n",
      "Epoch 00168: val_loss improved from 0.00965 to 0.00960, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0103 - root_mean_squared_error: 0.1012 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 169/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0140 - root_mean_squared_error: 0.1185\n",
      "Epoch 00169: val_loss improved from 0.00960 to 0.00955, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0102 - root_mean_squared_error: 0.1010 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 170/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0139 - root_mean_squared_error: 0.1181\n",
      "Epoch 00170: val_loss improved from 0.00955 to 0.00951, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0101 - root_mean_squared_error: 0.1007 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0975\n",
      "Epoch 171/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0139 - root_mean_squared_error: 0.1177\n",
      "Epoch 00171: val_loss improved from 0.00951 to 0.00946, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0101 - root_mean_squared_error: 0.1005 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 172/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0138 - root_mean_squared_error: 0.1173\n",
      "Epoch 00172: val_loss improved from 0.00946 to 0.00942, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0100 - root_mean_squared_error: 0.1002 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 173/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0137 - root_mean_squared_error: 0.1169\n",
      "Epoch 00173: val_loss improved from 0.00942 to 0.00938, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0100 - root_mean_squared_error: 0.1000 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 174/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0136 - root_mean_squared_error: 0.1166\n",
      "Epoch 00174: val_loss improved from 0.00938 to 0.00934, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 175/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0135 - root_mean_squared_error: 0.1162\n",
      "Epoch 00175: val_loss improved from 0.00934 to 0.00930, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0099 - root_mean_squared_error: 0.0995 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 176/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0134 - root_mean_squared_error: 0.1158\n",
      "Epoch 00176: val_loss improved from 0.00930 to 0.00926, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0099 - root_mean_squared_error: 0.0993 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0962\n",
      "Epoch 177/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0133 - root_mean_squared_error: 0.1155\n",
      "Epoch 00177: val_loss improved from 0.00926 to 0.00922, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0098 - root_mean_squared_error: 0.0990 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 178/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0133 - root_mean_squared_error: 0.1151\n",
      "Epoch 00178: val_loss improved from 0.00922 to 0.00918, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0098 - root_mean_squared_error: 0.0988 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 179/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0132 - root_mean_squared_error: 0.1148\n",
      "Epoch 00179: val_loss improved from 0.00918 to 0.00915, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0097 - root_mean_squared_error: 0.0986 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 180/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0131 - root_mean_squared_error: 0.1144\n",
      "Epoch 00180: val_loss improved from 0.00915 to 0.00911, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0097 - root_mean_squared_error: 0.0984 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 181/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0130 - root_mean_squared_error: 0.1141\n",
      "Epoch 00181: val_loss improved from 0.00911 to 0.00908, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0953\n",
      "Epoch 182/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0129 - root_mean_squared_error: 0.1137\n",
      "Epoch 00182: val_loss improved from 0.00908 to 0.00904, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0096 - root_mean_squared_error: 0.0979 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 183/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0129 - root_mean_squared_error: 0.1134\n",
      "Epoch 00183: val_loss improved from 0.00904 to 0.00901, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0095 - root_mean_squared_error: 0.0977 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0128 - root_mean_squared_error: 0.1131\n",
      "Epoch 00184: val_loss improved from 0.00901 to 0.00898, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0095 - root_mean_squared_error: 0.0975 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 185/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0127 - root_mean_squared_error: 0.1128\n",
      "Epoch 00185: val_loss improved from 0.00898 to 0.00895, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0095 - root_mean_squared_error: 0.0973 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 186/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0126 - root_mean_squared_error: 0.1125\n",
      "Epoch 00186: val_loss improved from 0.00895 to 0.00892, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0094 - root_mean_squared_error: 0.0971 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 187/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0126 - root_mean_squared_error: 0.1121\n",
      "Epoch 00187: val_loss improved from 0.00892 to 0.00889, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0094 - root_mean_squared_error: 0.0969 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0943\n",
      "Epoch 188/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0125 - root_mean_squared_error: 0.1118\n",
      "Epoch 00188: val_loss improved from 0.00889 to 0.00886, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0094 - root_mean_squared_error: 0.0967 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 189/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0124 - root_mean_squared_error: 0.1115\n",
      "Epoch 00189: val_loss improved from 0.00886 to 0.00883, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0093 - root_mean_squared_error: 0.0965 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 190/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0124 - root_mean_squared_error: 0.1112\n",
      "Epoch 00190: val_loss improved from 0.00883 to 0.00880, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0093 - root_mean_squared_error: 0.0963 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0938\n",
      "Epoch 191/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0123 - root_mean_squared_error: 0.1110\n",
      "Epoch 00191: val_loss improved from 0.00880 to 0.00878, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0092 - root_mean_squared_error: 0.0961 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0937\n",
      "Epoch 192/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0122 - root_mean_squared_error: 0.1107\n",
      "Epoch 00192: val_loss improved from 0.00878 to 0.00875, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0935\n",
      "Epoch 193/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0122 - root_mean_squared_error: 0.1104\n",
      "Epoch 00193: val_loss improved from 0.00875 to 0.00873, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0092 - root_mean_squared_error: 0.0958 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0934\n",
      "Epoch 194/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0121 - root_mean_squared_error: 0.1101\n",
      "Epoch 00194: val_loss improved from 0.00873 to 0.00870, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0091 - root_mean_squared_error: 0.0956 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 195/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0121 - root_mean_squared_error: 0.1098\n",
      "Epoch 00195: val_loss improved from 0.00870 to 0.00868, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0091 - root_mean_squared_error: 0.0954 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0931\n",
      "Epoch 196/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0120 - root_mean_squared_error: 0.1096\n",
      "Epoch 00196: val_loss improved from 0.00868 to 0.00865, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0091 - root_mean_squared_error: 0.0952 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 197/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0120 - root_mean_squared_error: 0.1093\n",
      "Epoch 00197: val_loss improved from 0.00865 to 0.00863, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0090 - root_mean_squared_error: 0.0951 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 198/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0119 - root_mean_squared_error: 0.1091\n",
      "Epoch 00198: val_loss improved from 0.00863 to 0.00861, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0090 - root_mean_squared_error: 0.0949 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 199/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0118 - root_mean_squared_error: 0.1088\n",
      "Epoch 00199: val_loss improved from 0.00861 to 0.00859, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0090 - root_mean_squared_error: 0.0947 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0927\n",
      "Epoch 200/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0118 - root_mean_squared_error: 0.1086\n",
      "Epoch 00200: val_loss improved from 0.00859 to 0.00856, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0089 - root_mean_squared_error: 0.0946 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 201/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0117 - root_mean_squared_error: 0.1083\n",
      "Epoch 00201: val_loss improved from 0.00856 to 0.00854, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0089 - root_mean_squared_error: 0.0944 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 202/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0117 - root_mean_squared_error: 0.1081\n",
      "Epoch 00202: val_loss improved from 0.00854 to 0.00852, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0089 - root_mean_squared_error: 0.0943 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0923\n",
      "Epoch 203/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0116 - root_mean_squared_error: 0.1079\n",
      "Epoch 00203: val_loss improved from 0.00852 to 0.00850, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0089 - root_mean_squared_error: 0.0941 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 204/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0116 - root_mean_squared_error: 0.1076\n",
      "Epoch 00204: val_loss improved from 0.00850 to 0.00848, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0088 - root_mean_squared_error: 0.0940 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 205/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0115 - root_mean_squared_error: 0.1074\n",
      "Epoch 00205: val_loss improved from 0.00848 to 0.00847, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0088 - root_mean_squared_error: 0.0938 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 206/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0115 - root_mean_squared_error: 0.1072\n",
      "Epoch 00206: val_loss improved from 0.00847 to 0.00845, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0088 - root_mean_squared_error: 0.0937 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0114 - root_mean_squared_error: 0.1070\n",
      "Epoch 00207: val_loss improved from 0.00845 to 0.00843, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 208/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0114 - root_mean_squared_error: 0.1068\n",
      "Epoch 00208: val_loss improved from 0.00843 to 0.00841, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0087 - root_mean_squared_error: 0.0934 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 209/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0114 - root_mean_squared_error: 0.1065\n",
      "Epoch 00209: val_loss improved from 0.00841 to 0.00840, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0087 - root_mean_squared_error: 0.0933 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 210/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0113 - root_mean_squared_error: 0.1063\n",
      "Epoch 00210: val_loss improved from 0.00840 to 0.00838, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0087 - root_mean_squared_error: 0.0931 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 211/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0113 - root_mean_squared_error: 0.1061\n",
      "Epoch 00211: val_loss improved from 0.00838 to 0.00836, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0086 - root_mean_squared_error: 0.0930 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 212/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0112 - root_mean_squared_error: 0.1060\n",
      "Epoch 00212: val_loss improved from 0.00836 to 0.00835, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0086 - root_mean_squared_error: 0.0929 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 213/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0112 - root_mean_squared_error: 0.1058\n",
      "Epoch 00213: val_loss improved from 0.00835 to 0.00833, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0086 - root_mean_squared_error: 0.0927 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0913\n",
      "Epoch 214/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0111 - root_mean_squared_error: 0.1056\n",
      "Epoch 00214: val_loss improved from 0.00833 to 0.00832, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0086 - root_mean_squared_error: 0.0926 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 215/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0111 - root_mean_squared_error: 0.1054\n",
      "Epoch 00215: val_loss improved from 0.00832 to 0.00831, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0086 - root_mean_squared_error: 0.0925 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 216/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0111 - root_mean_squared_error: 0.1052\n",
      "Epoch 00216: val_loss improved from 0.00831 to 0.00829, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0085 - root_mean_squared_error: 0.0924 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 217/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0110 - root_mean_squared_error: 0.1050\n",
      "Epoch 00217: val_loss improved from 0.00829 to 0.00828, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0085 - root_mean_squared_error: 0.0922 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0910\n",
      "Epoch 218/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0110 - root_mean_squared_error: 0.1049\n",
      "Epoch 00218: val_loss improved from 0.00828 to 0.00827, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0085 - root_mean_squared_error: 0.0921 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 219/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0110 - root_mean_squared_error: 0.1047\n",
      "Epoch 00219: val_loss improved from 0.00827 to 0.00825, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0085 - root_mean_squared_error: 0.0920 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 220/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0109 - root_mean_squared_error: 0.1045\n",
      "Epoch 00220: val_loss improved from 0.00825 to 0.00824, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 221/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0109 - root_mean_squared_error: 0.1044\n",
      "Epoch 00221: val_loss improved from 0.00824 to 0.00823, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - root_mean_squared_error: 0.0918 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n",
      "Epoch 222/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0109 - root_mean_squared_error: 0.1042\n",
      "Epoch 00222: val_loss improved from 0.00823 to 0.00822, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - root_mean_squared_error: 0.0917 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n",
      "Epoch 223/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0108 - root_mean_squared_error: 0.1041\n",
      "Epoch 00223: val_loss improved from 0.00822 to 0.00821, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0084 - root_mean_squared_error: 0.0916 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0906\n",
      "Epoch 224/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0108 - root_mean_squared_error: 0.1039\n",
      "Epoch 00224: val_loss improved from 0.00821 to 0.00820, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0905\n",
      "Epoch 225/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0108 - root_mean_squared_error: 0.1038\n",
      "Epoch 00225: val_loss improved from 0.00820 to 0.00819, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0083 - root_mean_squared_error: 0.0914 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0905\n",
      "Epoch 226/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0087 - root_mean_squared_error: 0.0932\n",
      "Epoch 00226: val_loss improved from 0.00819 to 0.00818, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0083 - root_mean_squared_error: 0.0913 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 227/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0107 - root_mean_squared_error: 0.1035\n",
      "Epoch 00227: val_loss improved from 0.00818 to 0.00817, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0083 - root_mean_squared_error: 0.0912 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 228/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0107 - root_mean_squared_error: 0.1034\n",
      "Epoch 00228: val_loss improved from 0.00817 to 0.00816, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0083 - root_mean_squared_error: 0.0911 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0903\n",
      "Epoch 229/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0107 - root_mean_squared_error: 0.1032\n",
      "Epoch 00229: val_loss improved from 0.00816 to 0.00815, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0083 - root_mean_squared_error: 0.0910 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0106 - root_mean_squared_error: 0.1031\n",
      "Epoch 00230: val_loss improved from 0.00815 to 0.00814, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0083 - root_mean_squared_error: 0.0909 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0902\n",
      "Epoch 231/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0106 - root_mean_squared_error: 0.1030\n",
      "Epoch 00231: val_loss improved from 0.00814 to 0.00813, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0902\n",
      "Epoch 232/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0106 - root_mean_squared_error: 0.1028\n",
      "Epoch 00232: val_loss improved from 0.00813 to 0.00812, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0082 - root_mean_squared_error: 0.0907 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0901\n",
      "Epoch 233/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0105 - root_mean_squared_error: 0.1027\n",
      "Epoch 00233: val_loss improved from 0.00812 to 0.00811, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0082 - root_mean_squared_error: 0.0906 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0901\n",
      "Epoch 234/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0105 - root_mean_squared_error: 0.1026\n",
      "Epoch 00234: val_loss improved from 0.00811 to 0.00811, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0082 - root_mean_squared_error: 0.0905 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0900\n",
      "Epoch 235/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0105 - root_mean_squared_error: 0.1025\n",
      "Epoch 00235: val_loss improved from 0.00811 to 0.00810, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0082 - root_mean_squared_error: 0.0905 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0900\n",
      "Epoch 236/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0105 - root_mean_squared_error: 0.1024\n",
      "Epoch 00236: val_loss improved from 0.00810 to 0.00809, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0082 - root_mean_squared_error: 0.0904 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0899\n",
      "Epoch 237/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0105 - root_mean_squared_error: 0.1022\n",
      "Epoch 00237: val_loss improved from 0.00809 to 0.00808, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0899\n",
      "Epoch 238/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0104 - root_mean_squared_error: 0.1021\n",
      "Epoch 00238: val_loss improved from 0.00808 to 0.00808, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0081 - root_mean_squared_error: 0.0902 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0899\n",
      "Epoch 239/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0104 - root_mean_squared_error: 0.1020\n",
      "Epoch 00239: val_loss improved from 0.00808 to 0.00807, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 240/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0104 - root_mean_squared_error: 0.1019\n",
      "Epoch 00240: val_loss improved from 0.00807 to 0.00806, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 241/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0104 - root_mean_squared_error: 0.1018\n",
      "Epoch 00241: val_loss improved from 0.00806 to 0.00806, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0081 - root_mean_squared_error: 0.0900 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 242/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0103 - root_mean_squared_error: 0.1017\n",
      "Epoch 00242: val_loss improved from 0.00806 to 0.00805, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0897\n",
      "Epoch 243/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0103 - root_mean_squared_error: 0.1016\n",
      "Epoch 00243: val_loss improved from 0.00805 to 0.00804, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0081 - root_mean_squared_error: 0.0898 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0897\n",
      "Epoch 244/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0103 - root_mean_squared_error: 0.1015\n",
      "Epoch 00244: val_loss improved from 0.00804 to 0.00804, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0081 - root_mean_squared_error: 0.0898 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0897\n",
      "Epoch 245/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0103 - root_mean_squared_error: 0.1014\n",
      "Epoch 00245: val_loss improved from 0.00804 to 0.00803, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0080 - root_mean_squared_error: 0.0897 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0896\n",
      "Epoch 246/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0103 - root_mean_squared_error: 0.1013\n",
      "Epoch 00246: val_loss improved from 0.00803 to 0.00803, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0080 - root_mean_squared_error: 0.0896 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0896\n",
      "Epoch 247/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0103 - root_mean_squared_error: 0.1013\n",
      "Epoch 00247: val_loss improved from 0.00803 to 0.00802, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0080 - root_mean_squared_error: 0.0896 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0896\n",
      "Epoch 248/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0102 - root_mean_squared_error: 0.1012\n",
      "Epoch 00248: val_loss improved from 0.00802 to 0.00802, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0080 - root_mean_squared_error: 0.0895 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 249/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0102 - root_mean_squared_error: 0.1011\n",
      "Epoch 00249: val_loss improved from 0.00802 to 0.00801, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0080 - root_mean_squared_error: 0.0894 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 250/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0102 - root_mean_squared_error: 0.1010\n",
      "Epoch 00250: val_loss improved from 0.00801 to 0.00801, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0080 - root_mean_squared_error: 0.0894 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 251/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0102 - root_mean_squared_error: 0.1009\n",
      "Epoch 00251: val_loss improved from 0.00801 to 0.00800, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0080 - root_mean_squared_error: 0.0893 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 252/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0102 - root_mean_squared_error: 0.1008\n",
      "Epoch 00252: val_loss improved from 0.00800 to 0.00800, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0080 - root_mean_squared_error: 0.0893 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0102 - root_mean_squared_error: 0.1008\n",
      "Epoch 00253: val_loss improved from 0.00800 to 0.00800, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0080 - root_mean_squared_error: 0.0892 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 254/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0101 - root_mean_squared_error: 0.1007\n",
      "Epoch 00254: val_loss improved from 0.00800 to 0.00799, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0079 - root_mean_squared_error: 0.0891 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 255/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0101 - root_mean_squared_error: 0.1006\n",
      "Epoch 00255: val_loss improved from 0.00799 to 0.00799, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0079 - root_mean_squared_error: 0.0891 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 256/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0101 - root_mean_squared_error: 0.1005\n",
      "Epoch 00256: val_loss improved from 0.00799 to 0.00798, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0079 - root_mean_squared_error: 0.0890 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 257/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0101 - root_mean_squared_error: 0.1005\n",
      "Epoch 00257: val_loss improved from 0.00798 to 0.00798, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0079 - root_mean_squared_error: 0.0890 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0893\n",
      "Epoch 258/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0101 - root_mean_squared_error: 0.1004\n",
      "Epoch 00258: val_loss improved from 0.00798 to 0.00798, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0079 - root_mean_squared_error: 0.0889 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0893\n",
      "Epoch 259/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0101 - root_mean_squared_error: 0.1003\n",
      "Epoch 00259: val_loss improved from 0.00798 to 0.00797, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0079 - root_mean_squared_error: 0.0889 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0893\n",
      "Epoch 260/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0101 - root_mean_squared_error: 0.1003\n",
      "Epoch 00260: val_loss improved from 0.00797 to 0.00797, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0079 - root_mean_squared_error: 0.0888 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0893\n",
      "Epoch 261/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0100 - root_mean_squared_error: 0.1002\n",
      "Epoch 00261: val_loss improved from 0.00797 to 0.00797, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0079 - root_mean_squared_error: 0.0888 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0893\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0079 - root_mean_squared_error: 0.0887\n",
      "Epoch 00262: val_loss improved from 0.00797 to 0.00796, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0079 - root_mean_squared_error: 0.0887 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 263/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0100 - root_mean_squared_error: 0.1001\n",
      "Epoch 00263: val_loss improved from 0.00796 to 0.00796, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0079 - root_mean_squared_error: 0.0887 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 264/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0100 - root_mean_squared_error: 0.1000\n",
      "Epoch 00264: val_loss improved from 0.00796 to 0.00796, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0079 - root_mean_squared_error: 0.0886 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 265/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0100 - root_mean_squared_error: 0.0999\n",
      "Epoch 00265: val_loss improved from 0.00796 to 0.00796, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 266/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0100 - root_mean_squared_error: 0.0999\n",
      "Epoch 00266: val_loss improved from 0.00796 to 0.00795, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0078 - root_mean_squared_error: 0.0885 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 267/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0100 - root_mean_squared_error: 0.0998\n",
      "Epoch 00267: val_loss improved from 0.00795 to 0.00795, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0078 - root_mean_squared_error: 0.0885 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 268/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0100 - root_mean_squared_error: 0.0998\n",
      "Epoch 00268: val_loss improved from 0.00795 to 0.00795, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0078 - root_mean_squared_error: 0.0884 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 269/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0099 - root_mean_squared_error: 0.0997\n",
      "Epoch 00269: val_loss improved from 0.00795 to 0.00795, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0078 - root_mean_squared_error: 0.0884 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 270/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0099 - root_mean_squared_error: 0.0997\n",
      "Epoch 00270: val_loss improved from 0.00795 to 0.00794, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0078 - root_mean_squared_error: 0.0883 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 271/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0099 - root_mean_squared_error: 0.0996\n",
      "Epoch 00271: val_loss improved from 0.00794 to 0.00794, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0078 - root_mean_squared_error: 0.0883 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 272/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0099 - root_mean_squared_error: 0.0996\n",
      "Epoch 00272: val_loss improved from 0.00794 to 0.00794, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0078 - root_mean_squared_error: 0.0882 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 273/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0099 - root_mean_squared_error: 0.0995\n",
      "Epoch 00273: val_loss improved from 0.00794 to 0.00794, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0078 - root_mean_squared_error: 0.0882 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 274/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0099 - root_mean_squared_error: 0.0994\n",
      "Epoch 00274: val_loss improved from 0.00794 to 0.00794, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0078 - root_mean_squared_error: 0.0882 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 275/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0099 - root_mean_squared_error: 0.0994\n",
      "Epoch 00275: val_loss improved from 0.00794 to 0.00793, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0078 - root_mean_squared_error: 0.0881 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0099 - root_mean_squared_error: 0.0993\n",
      "Epoch 00276: val_loss improved from 0.00793 to 0.00793, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0078 - root_mean_squared_error: 0.0881 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 277/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0099 - root_mean_squared_error: 0.0993\n",
      "Epoch 00277: val_loss improved from 0.00793 to 0.00793, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0078 - root_mean_squared_error: 0.0880 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 278/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0099 - root_mean_squared_error: 0.0993\n",
      "Epoch 00278: val_loss improved from 0.00793 to 0.00793, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0077 - root_mean_squared_error: 0.0880 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 279/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0992\n",
      "Epoch 00279: val_loss improved from 0.00793 to 0.00793, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0077 - root_mean_squared_error: 0.0880 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 280/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0992\n",
      "Epoch 00280: val_loss improved from 0.00793 to 0.00793, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0077 - root_mean_squared_error: 0.0879 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 281/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0991\n",
      "Epoch 00281: val_loss improved from 0.00793 to 0.00792, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0077 - root_mean_squared_error: 0.0879 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 282/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0991\n",
      "Epoch 00282: val_loss improved from 0.00792 to 0.00792, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0077 - root_mean_squared_error: 0.0879 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 283/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0990\n",
      "Epoch 00283: val_loss improved from 0.00792 to 0.00792, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0077 - root_mean_squared_error: 0.0878 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 284/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0990\n",
      "Epoch 00284: val_loss improved from 0.00792 to 0.00792, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0077 - root_mean_squared_error: 0.0878 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 285/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0989\n",
      "Epoch 00285: val_loss improved from 0.00792 to 0.00792, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0077 - root_mean_squared_error: 0.0878 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 286/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0989\n",
      "Epoch 00286: val_loss improved from 0.00792 to 0.00792, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0077 - root_mean_squared_error: 0.0877 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 287/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0989\n",
      "Epoch 00287: val_loss improved from 0.00792 to 0.00792, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0077 - root_mean_squared_error: 0.0877 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 288/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0988\n",
      "Epoch 00288: val_loss improved from 0.00792 to 0.00792, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0077 - root_mean_squared_error: 0.0877 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 289/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0988\n",
      "Epoch 00289: val_loss improved from 0.00792 to 0.00791, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0077 - root_mean_squared_error: 0.0876 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 290/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0987\n",
      "Epoch 00290: val_loss improved from 0.00791 to 0.00791, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0077 - root_mean_squared_error: 0.0876 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 291/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0987\n",
      "Epoch 00291: val_loss improved from 0.00791 to 0.00791, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0077 - root_mean_squared_error: 0.0876 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 292/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0987\n",
      "Epoch 00292: val_loss improved from 0.00791 to 0.00791, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0077 - root_mean_squared_error: 0.0875 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 293/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0986\n",
      "Epoch 00293: val_loss improved from 0.00791 to 0.00791, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0077 - root_mean_squared_error: 0.0875 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 294/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0986\n",
      "Epoch 00294: val_loss improved from 0.00791 to 0.00791, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0077 - root_mean_squared_error: 0.0875 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 295/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0986\n",
      "Epoch 00295: val_loss improved from 0.00791 to 0.00791, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0874 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 296/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0985\n",
      "Epoch 00296: val_loss improved from 0.00791 to 0.00791, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0874 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 297/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0985\n",
      "Epoch 00297: val_loss improved from 0.00791 to 0.00791, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0874 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 298/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0985\n",
      "Epoch 00298: val_loss improved from 0.00791 to 0.00791, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0076 - root_mean_squared_error: 0.0874 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0984\n",
      "Epoch 00299: val_loss improved from 0.00791 to 0.00791, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 300/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0984\n",
      "Epoch 00300: val_loss improved from 0.00791 to 0.00791, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 301/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0984\n",
      "Epoch 00301: val_loss improved from 0.00791 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 302/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0983\n",
      "Epoch 00302: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 303/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0983\n",
      "Epoch 00303: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 304/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0983\n",
      "Epoch 00304: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 305/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0982\n",
      "Epoch 00305: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 306/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0982\n",
      "Epoch 00306: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 307/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0982\n",
      "Epoch 00307: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 308/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0981\n",
      "Epoch 00308: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 309/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0981\n",
      "Epoch 00309: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 310/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0981\n",
      "Epoch 00310: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 311/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0981\n",
      "Epoch 00311: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 312/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0980\n",
      "Epoch 00312: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 313/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0980\n",
      "Epoch 00313: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 314/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0980\n",
      "Epoch 00314: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 315/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0979\n",
      "Epoch 00315: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 316/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0979\n",
      "Epoch 00316: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 317/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0979\n",
      "Epoch 00317: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0869 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 318/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0979\n",
      "Epoch 00318: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0869 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 319/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0978\n",
      "Epoch 00319: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0868 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 320/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0978\n",
      "Epoch 00320: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0868 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 321/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0978\n",
      "Epoch 00321: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0868 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 322/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0978\n",
      "Epoch 00322: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0868 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 323/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0977\n",
      "Epoch 00323: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0868 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 324/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0977\n",
      "Epoch 00324: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0867 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 325/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0977\n",
      "Epoch 00325: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0867 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 326/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0977\n",
      "Epoch 00326: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0867 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 327/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0976\n",
      "Epoch 00327: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0867 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 328/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0976\n",
      "Epoch 00328: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0867 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 329/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0976\n",
      "Epoch 00329: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0866 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 330/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0976\n",
      "Epoch 00330: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0866 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 331/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0975\n",
      "Epoch 00331: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0866 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 332/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0975\n",
      "Epoch 00332: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0866 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 333/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0975\n",
      "Epoch 00333: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0866 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 334/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0975\n",
      "Epoch 00334: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0075 - root_mean_squared_error: 0.0865 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 335/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0975\n",
      "Epoch 00335: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0865 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 336/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0974\n",
      "Epoch 00336: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0075 - root_mean_squared_error: 0.0865 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 337/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0974\n",
      "Epoch 00337: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0865 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 338/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0974\n",
      "Epoch 00338: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0075 - root_mean_squared_error: 0.0865 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 339/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0974\n",
      "Epoch 00339: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0075 - root_mean_squared_error: 0.0865 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 340/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0974\n",
      "Epoch 00340: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0075 - root_mean_squared_error: 0.0864 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 341/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0973\n",
      "Epoch 00341: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0864 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 342/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0973\n",
      "Epoch 00342: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0864 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 343/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0973\n",
      "Epoch 00343: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0075 - root_mean_squared_error: 0.0864 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0973\n",
      "Epoch 00344: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0075 - root_mean_squared_error: 0.0864 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 345/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0972\n",
      "Epoch 00345: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0864 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 346/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0972\n",
      "Epoch 00346: val_loss improved from 0.00790 to 0.00790, saving model to ../out/union/lstm/cp.ckpt\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0863 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 347/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0094 - root_mean_squared_error: 0.0972\n",
      "Epoch 00347: val_loss did not improve from 0.00790\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0075 - root_mean_squared_error: 0.0863 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 348/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0094 - root_mean_squared_error: 0.0972\n",
      "Epoch 00348: val_loss did not improve from 0.00790\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0074 - root_mean_squared_error: 0.0863 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 349/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0094 - root_mean_squared_error: 0.0972\n",
      "Epoch 00349: val_loss did not improve from 0.00790\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0074 - root_mean_squared_error: 0.0863 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 350/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0094 - root_mean_squared_error: 0.0972\n",
      "Epoch 00350: val_loss did not improve from 0.00790\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0074 - root_mean_squared_error: 0.0863 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 351/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0094 - root_mean_squared_error: 0.0971\n",
      "Epoch 00351: val_loss did not improve from 0.00790\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0074 - root_mean_squared_error: 0.0863 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 00351: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    os.path.join(out_dir,'cp.ckpt'), \n",
    "    monitor='val_loss', \n",
    "    save_weights_only=True, \n",
    "    verbose=1, \n",
    "    save_best_only=True\n",
    "    )\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=10, verbose=1,\n",
    "    mode='auto', min_delta=0.0001, cooldown=0, min_lr=1e-10\n",
    ")\n",
    "\n",
    "early_stopping = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor=\"val_loss\",\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=0,\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        patience=5,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "epochs = 1000\n",
    "model_history = model.fit(train_dataset,\n",
    "                          epochs = epochs,\n",
    "                          validation_data = val_dataset,\n",
    "                          callbacks = [checkpoint, early_stopping]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights(os.path.join(out_dir, 'cp.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "cQpDS_YhajeP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f53801d1d90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the best weights\n",
    "model.load_weights(os.path.join(out_dir, 'cp.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "C9hur5ABktOI",
    "outputId": "ed88d296-d8b0-4a83-8e96-1937e4923c26"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot epoch vs loss, epoch vs RMSE\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "epochs = len(model_history.history['loss'])\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(0,epochs,1), model_history.history['loss'], '-', label='train_loss')\n",
    "plt.plot(np.arange(0,epochs,1), model_history.history['val_loss'], '--', label='val_loss', )\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('MeanSquaredLoss')\n",
    "#plt.title('epoch vs loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(0,epochs,1), model_history.history['root_mean_squared_error'], '-', label='train_rmse')\n",
    "plt.plot(np.arange(0,epochs,1), model_history.history['val_root_mean_squared_error'], '--', label='val_rmse')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('RMSE')\n",
    "#plt.title('epoch vs RMSE')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(out_dir,'05_epoch_vs_loss.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "g__uGFnmkySW"
   },
   "outputs": [],
   "source": [
    "#model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "tJl9Sye_UjUS"
   },
   "outputs": [],
   "source": [
    "# Reconstruct \n",
    "z_reconstruct = np.linspace(0,8.5,212)[::-1]\n",
    "z_reconstruct = np.expand_dims(strided_app(z_reconstruct, window_size, 1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "LxXx6jz0DMWc"
   },
   "outputs": [],
   "source": [
    "mu_reconstruct = model.predict(z_reconstruct, batch_size=BATCH_SIZE)\n",
    "mu_reconstruct = mu_scaler.inverse_transform(mu_reconstruct.reshape(-1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "3CK_F3C0IwR0",
    "outputId": "8377ff59-db1c-4cde-cfaa-37582da942e7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot reconstructed z vs mu\n",
    "plt.plot(z_reconstruct[:,-1].flatten(), mu_reconstruct[:,-1].flatten(), '.',color='b');\n",
    "plt.xlabel('redshift(z)')\n",
    "plt.ylabel('distance modulus(mu)')\n",
    "#plt.title('Distance modulus vs redshift')\n",
    "plt.savefig(os.path.join(out_dir,'06_sample_reconstruction.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Reconstruction with uncertainity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "KnX3h6Q53PzN"
   },
   "outputs": [],
   "source": [
    "model_u = model_uncertainity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1z6LLXtS3GJo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f53780b45b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_u.load_weights(os.path.join(out_dir,'cp.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "5FyLzv8BaTyT"
   },
   "outputs": [],
   "source": [
    "model_u.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss=tf.keras.losses.MeanSquaredError(), metrics=tf.keras.metrics.RootMeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_reconstruct_uncertainity = []\n",
    "n = 1000\n",
    "for i in range(n):\n",
    "    y_pred = model_u.predict(z_reconstruct, batch_size=500)[:,-1].flatten()\n",
    "    y_pred = mu_scaler.inverse_transform(y_pred.reshape(-1,1))\n",
    "    mu_reconstruct_uncertainity.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "9LoRnjc3Erwt"
   },
   "outputs": [],
   "source": [
    "mu_reconstruct_uncertainity = np.array(mu_reconstruct_uncertainity)\n",
    "mean = np.mean(mu_reconstruct_uncertainity, axis=0).flatten()\n",
    "std_dev = np.std(mu_reconstruct_uncertainity, axis=0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_reconstruct = z_scaler.inverse_transform(z_reconstruct[:,-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "EZGXBrCkHl1E",
    "outputId": "1084c1fe-58bd-4444-d32b-0b86c43206c4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_178825/344823818.py:16: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \".r\" (-> color='r'). The keyword argument will take precedence.\n",
      "  plt.errorbar(df_SNe['zCMB'], df_SNe['MU'], yerr=df_SNe['MUERR'], fmt='.r', label=dataset+' Sample', color='r');\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(figsize=(10,7))\n",
    "plt.fill_between(\n",
    "    z_reconstruct[:,-1].flatten(), \n",
    "    mean-3*std_dev, mean+3*std_dev,\n",
    "    label='Reconstruction in 3 sigma',color='b', alpha=0.1)\n",
    "plt.fill_between(\n",
    "    z_reconstruct[:,-1].flatten(), \n",
    "    mean-2*std_dev, mean+2*std_dev,\n",
    "    label='Reconstruction in 2 sigma',color='b', alpha=0.3)\n",
    "plt.fill_between(\n",
    "    z_reconstruct[:,-1].flatten(), \n",
    "    mean-1*std_dev, mean+1*std_dev,\n",
    "    label='Reconstruction in 1 sigma', color='b', alpha=0.4)\n",
    "\n",
    "plt.plot(z_reconstruct[:,-1].flatten(), mean, label='Reconstruction', color='k')\n",
    "plt.errorbar(df_SNe['zCMB'], df_SNe['MU'], yerr=df_SNe['MUERR'], fmt='.r', label=dataset+' Sample', color='r');\n",
    "plt.xlabel('redshift(z)')\n",
    "plt.ylabel('distance modulus(mu)')\n",
    "#plt.title('The reconstruction of distance moduli from '+dataset+' data ')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(out_dir,'07_sample_reconstruction_with_uncertainity.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "01-.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
